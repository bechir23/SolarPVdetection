{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "009f78da-dd77-4223-8982-1a0b73702563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and load the model\n",
    "model = HybridModel(num_classes=2)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load('runs1/best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0e1b0f-e31d-4da8-8c1e-e364baa52a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in original model: 423410282\n",
      "Number of trainable parameters in original model: 423410282\n"
     ]
    }
   ],
   "source": [
    "def get_total_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Calculate parameters\n",
    "total_params = get_total_parameters(model)\n",
    "trainable_params = get_trainable_parameters(model)\n",
    "print(f\"Total number of parameters in original model: {total_params}\")\n",
    "print(f\"Number of trainable parameters in original model: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f89291b-3037-470b-b5f7-528dc4198262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of 'best.pt': 1616.32 MB\n"
     ]
    }
   ],
   "source": [
    "final_model_size=os.path.getsize('runs1/best.pt')\n",
    "print(f\"Size of 'best.pt': {final_model_size / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea65437-fd49-4d52-af31-b36686c4d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Gathering statistics:   0%|          | 0/728 [00:00<?, ?it/s]`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "Gathering statistics: 100%|██████████| 728/728 [05:05<00:00,  2.38it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Quantized cudnn conv2d is currently limited to groups = 1; received groups =64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m model_pruned \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDataParallel(model_pruned)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Apply quantization\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m model_quantized \u001b[38;5;241m=\u001b[39m \u001b[43mapply_quantization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_pruned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Save the quantized model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_quantized\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns1/quantized_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36mapply_quantization\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     38\u001b[0m         model(inputs)  \u001b[38;5;66;03m# Forward pass to gather statistics\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Convert the model to a quantized version\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:563\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m    562\u001b[0m     module \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(module)\n\u001b[0;32m--> 563\u001b[0m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_qconfig:\n\u001b[1;32m    568\u001b[0m     _remove_qconfig(module)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:604\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    603\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 604\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[1;32m    605\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:604\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    603\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 604\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[1;32m    605\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
      "    \u001b[0;31m[... skipping similar frames: _convert at line 604 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:604\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, mod \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_children():\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;66;03m# both fused modules and observed custom modules are\u001b[39;00m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;66;03m# swapped as one unit\u001b[39;00m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    603\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[0;32m--> 604\u001b[0m         \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# inplace\u001b[39;49;00m\n\u001b[1;32m    605\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mis_reference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:607\u001b[0m, in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, _FusedModule) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    603\u001b[0m        type_before_parametrizations(mod) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m custom_module_class_mapping:\n\u001b[1;32m    604\u001b[0m         _convert(mod, mapping, \u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# inplace\u001b[39;00m\n\u001b[1;32m    605\u001b[0m                  is_reference, convert_custom_config_dict,\n\u001b[1;32m    606\u001b[0m                  use_precomputed_fake_quant\u001b[38;5;241m=\u001b[39muse_precomputed_fake_quant)\n\u001b[0;32m--> 607\u001b[0m     reassign[name] \u001b[38;5;241m=\u001b[39m \u001b[43mswap_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_module_class_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m reassign\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    610\u001b[0m     module\u001b[38;5;241m.\u001b[39m_modules[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/quantization/quantize.py:642\u001b[0m, in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    640\u001b[0m sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(qmod\u001b[38;5;241m.\u001b[39mfrom_float)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_precomputed_fake_quant\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[0;32m--> 642\u001b[0m     new_mod \u001b[38;5;241m=\u001b[39m \u001b[43mqmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m     new_mod \u001b[38;5;241m=\u001b[39m qmod\u001b[38;5;241m.\u001b[39mfrom_float(mod)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:480\u001b[0m, in \u001b[0;36mConv2d.from_float\u001b[0;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_float\u001b[39m(\u001b[38;5;28mcls\u001b[39m, mod, use_precomputed_fake_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    474\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a quantized module from a float module or qparams_dict.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m        mod (Module): a float module, either produced by torch.ao.quantization\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m          utilities or provided by the user\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConvNd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_float\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_precomputed_fake_quant\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:242\u001b[0m, in \u001b[0;36m_ConvNd.from_float\u001b[0;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    240\u001b[0m         mod \u001b[38;5;241m=\u001b[39m mod[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    241\u001b[0m     weight_post_process \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mqconfig\u001b[38;5;241m.\u001b[39mweight()\n\u001b[0;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_qconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_post_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_post_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:209\u001b[0m, in \u001b[0;36m_ConvNd.get_qconv\u001b[0;34m(cls, mod, activation_post_process, weight_post_process)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# the __init__ call used is the one from derived classes and not the one from _ConvNd\u001b[39;00m\n\u001b[1;32m    206\u001b[0m qconv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(mod\u001b[38;5;241m.\u001b[39min_channels, mod\u001b[38;5;241m.\u001b[39mout_channels, mod\u001b[38;5;241m.\u001b[39mkernel_size,\n\u001b[1;32m    207\u001b[0m             mod\u001b[38;5;241m.\u001b[39mstride, mod\u001b[38;5;241m.\u001b[39mpadding, mod\u001b[38;5;241m.\u001b[39mdilation, mod\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    208\u001b[0m             mod\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, mod\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 209\u001b[0m \u001b[43mqconv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weight_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m activation_post_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m activation_post_process\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qconv  \u001b[38;5;66;03m# dynamic quantization doesn't need scale/zero_point\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:445\u001b[0m, in \u001b[0;36mConv2d.set_weight_bias\u001b[0;34m(self, w, b)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_weight_bias\u001b[39m(\u001b[38;5;28mself\u001b[39m, w: torch\u001b[38;5;241m.\u001b[39mTensor, b: Optional[torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_prepack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packed_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mquantized\u001b[38;5;241m.\u001b[39mconv2d_prepack(\n\u001b[1;32m    449\u001b[0m             w, b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Quantized cudnn conv2d is currently limited to groups = 1; received groups =64"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.utils.prune as prune\n",
    "from tqdm import tqdm\n",
    "\n",
    "def apply_pruning(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            prune.l1_unstructured(module, name=\"weight\", amount=0.2)\n",
    "            prune.remove(module, 'weight')  \n",
    "    return model\n",
    "\n",
    "def apply_quantization(model, train_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    qconfig = torch.quantization.QConfig(\n",
    "        activation=torch.quantization.default_observer.with_args(dtype=torch.qint8),\n",
    "        weight=torch.quantization.default_weight_observer.with_args(dtype=torch.qint8)\n",
    "    )\n",
    "    \n",
    "    model.qconfig = qconfig\n",
    "\n",
    "    # Prepare the model for quantization\n",
    "    torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "    # Calibrate the model with training data\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in tqdm(train_loader, desc=\"Gathering statistics\"):\n",
    "            inputs = inputs.to(device)\n",
    "            model(inputs)  # Forward pass \n",
    "\n",
    "    # Convert the model to a quantized version\n",
    "    torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Apply pruning\n",
    "model_pruned = apply_pruning(model)\n",
    "\n",
    "model_pruned = nn.DataParallel(model_pruned)\n",
    "\n",
    "# Apply post-training quantization\n",
    "model_quantized = apply_quantization(model_pruned, train_loader)\n",
    "\n",
    "# Save the quantized model\n",
    "torch.save(model_quantized.state_dict(), 'runs1/quantized_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4483ff6-a7f8-4d42-9e95-7adf6333e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def fine_tune(model, num_epochs, criterion, optimizer, train_loader, valid_loader, scaler):\n",
    "    best_loss = float('inf')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    history = []\n",
    "    early_stop = 0\n",
    "    patience = 3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
    "\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            progress_bar.set_postfix(loss=running_loss / len(progress_bar))\n",
    "\n",
    "        validator_loss, metrics = validate_model(model, valid_loader, criterion)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        precision, recall, f1 = metrics['precision'], metrics['recall'], metrics['f1']\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Time: {epoch_time:.2f} seconds\")\n",
    "        print(f'Epoch: {epoch + 1} Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Loss: {validator_loss}')\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_matrix(metrics['confusion_matrix'])\n",
    "\n",
    "        history.append({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Loss': validator_loss\n",
    "        })\n",
    "\n",
    "        if validator_loss < best_loss:\n",
    "            best_loss = validator_loss\n",
    "            torch.save(model.state_dict(), 'quantization/best_quantized.pt') \n",
    "            early_stop = 0\n",
    "        else:\n",
    "            early_stop += 1\n",
    "\n",
    "        if early_stop >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), 'quantization/final_quantized.pt')  \n",
    "\n",
    "# Fine-tuning\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6, weight_decay=1e-5)\n",
    "scaler = GradScaler()\n",
    "fine_tune(model_quantized, 2, criterion, optimizer, train_loader, valid_loader, scaler) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
